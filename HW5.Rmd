---
title: "HW5"
output: html_document
---
```{r}
library(readr)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(ISLR)
library(tidyverse)
library(glmnet)
tidymodels_prefer()
```


# Question 1
```{r setup, include=FALSE}
install.packages("janitor")
library(janitor)
Pokemon <- read_csv("~/Downloads/homework-5/data/Pokemon.csv")
View(Pokemon)

Pokemon_clean <- clean_names(Pokemon)

```

The data's object and column names are all converted to snake case (words separated by underscores like_this). Clean_names() is useful because it handles every kind of messy column name that's present in the data set and makes it easier to call when piping with "%>%".

# Question 2
```{r}
#bar chart
Pokemon_clean %>%
  ggplot(aes(x=type_1)) +
  geom_bar()

table(Pokemon_clean$type_1)

#filter out by specific classes
Pokemon <- Pokemon_clean %>%
  filter(type_1 %in% c("Bug", "Fire", "Grass", "Normal", "Water", "Psychic"))

#factor type_1 and legendary
Pokemon$type_1 <- as.factor(Pokemon$type_1)
Pokemon$legendary <- as.factor(Pokemon$legendary)

sapply(Pokemon,class)
View(Pokemon)

```
There are 18 classes. The flying class appears to have very few Pokemon in comparison to the rest (4), but the fairy, fighting, flying, ice, poison, and steel are all classes that have less than 30 pokemon in it.  


# Question 3
```{r}
#initial split
set.seed(458)
Pokemon_split <- initial_split(Pokemon, strata = "type_1", prop = 0.7)
Pokemon_train <- training(Pokemon_split)
Pokemon_test <- testing(Pokemon_split)

dim(Pokemon_train)
dim(Pokemon_test)

pokemon_folds <- vfold_cv(Pokemon_train, v = 5, strata = "type_1")
pokemon_folds
```
Stratifying the folds can be useful in ensuring that each fold of the dataset has the same proportion of observations with a given label.

# Question 4
```{r}
#set up a recipe
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp + sp_def, Pokemon_train) %>%
  step_dummy(c(legendary, generation)) %>%
  step_normalize(all_predictors())

```
# Question 5
```{r}
pokemon_reg <- multinom_reg(mixture = 0, penalty = 0) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

pokemon_grid <- grid_regular(penalty(range = c(-5, 5)), mixture(range = c(0,1)), levels = 10)
pokemon_grid
```
10 (penalties) x 2 (mixtures) x 5 (folds) = 100 models that will be fitted when fitting to the folded data

# Question 6
```{r}
pokemon_spec <- multinom_reg(penalty = tune(), mixture = tune()) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

pokemon_workflow <- workflow() %>% 
  add_recipe(pokemon_recipe) %>% 
  add_model(pokemon_spec)

pokemon_res <- tune_grid(
  pokemon_workflow,
  resamples = pokemon_folds, 
  grid = pokemon_grid
)

pokemon_res

autoplot(pokemon_res)
collect_metrics(pokemon_res)
```
From the plot, it appears that smaller values of penalty and mixture produce better accuracy and ROC AUC.

# Question 7
```{r}
best_penalty <- select_best(pokemon_res, metric = "roc_auc")
best_penalty

pokemon_final <- finalize_workflow(pokemon_workflow, best_penalty)

pokemon_final_fit <- fit(pokemon_final, data = Pokemon_train)

augment(pokemon_final_fit, new_data = Pokemon_test) 
```

# Question 8
```{r}
augment(pokemon_final_fit, new_data = Pokemon_test) %>%
  roc_auc(truth = type_1, estimate = c(.pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal, .pred_Water, .pred_Psychic))

augment(pokemon_final_fit, new_data = Pokemon_test) %>%
  roc_curve(truth = type_1, estimate = c(.pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal, .pred_Water, .pred_Psychic)) %>%
  autoplot()

augment(pokemon_final_fit, new_data = Pokemon_test) %>%
  conf_mat(truth = type_1, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```
In terms of performance, bug, fire, grass, and normal are all the types that the model is best at predicting. Comparing each curve to one another and trying to average out the performance, I believe the model performed relatively accurate, since the psychic and water predictions were not as good as the other types. This may be because the psychic and water types had more missing values, more specifically, missing type 2 values that gave us less data to work with. 
